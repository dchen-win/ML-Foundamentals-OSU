{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6163f4a",
   "metadata": {
    "papermill": {
     "duration": 0.018945,
     "end_time": "2023-05-13T22:41:28.112925",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.093980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains two parts. **Part 1, Multiple Linear Regression**, provides you an opportunity to demonstrate your ability to apply course concepts by implementing a training function for multiple linear regression. **Part 2, California Housing Prices**, provides you an opportunity to practice using widely-used ML libraries and an ML workflow to solve a regression problem.\n",
    "\n",
    "**You do not need to complete Part 1 in order to complete Part 2**. If you get stuck on Part 1, and choose to work on Part 2, be sure that all of your code for Part 1 runs without error. You can comment out your code in Part 1 if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b915e53",
   "metadata": {
    "papermill": {
     "duration": 0.018581,
     "end_time": "2023-05-13T22:41:28.153740",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.135159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1: Implementing Multiple Linear Regression\n",
    "\n",
    "Given a simple MultipleLinearRegressor, and a simple training set of housing data, demonstrate your ability to implement a multiple linear regression model's `fit` function, such that it properly trains its linear model using gradient descent.\n",
    "\n",
    "## The UnivariateLinearRegressor\n",
    "\n",
    "Let's first review the UnivariateLinearRegressor, which you should find familiar, and you do not need to modify. Notice that the `fit` method uses a fixed number of iterations, only for simplicity and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8d363b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.196397Z",
     "iopub.status.busy": "2023-05-13T22:41:28.195977Z",
     "iopub.status.idle": "2023-05-13T22:41:28.217267Z",
     "shell.execute_reply": "2023-05-13T22:41:28.215144Z"
    },
    "papermill": {
     "duration": 0.043588,
     "end_time": "2023-05-13T22:41:28.221037",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.177449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnivariateLinearRegressor:\n",
    "\n",
    "    def __init__(self, w = 0, b = 0, alpha = 0.1):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for _ in range(0, 10):\n",
    "            delta_w = self.alpha * self._d_cost_function_w(x_train, y_train)\n",
    "            delta_b = self.alpha * self._d_cost_function_b(x_train, y_train)\n",
    "            self.w = self.w - delta_w\n",
    "            self.b = self.b - delta_b\n",
    "\n",
    "    def _d_cost_function_w(self, x_train, y_train):\n",
    "        sum = 0\n",
    "        for i in range(len(x_train)):\n",
    "            sum += (self.predict(x_train[i]) - y_train[i]) * x_train[i]\n",
    "        return sum / len(x_train)\n",
    "\n",
    "    def _d_cost_function_b(self, x_train, y_train):\n",
    "        sum = 0\n",
    "        for i in range(len(x_train)):\n",
    "            sum += (self.predict(x_train[i]) - y_train[i])\n",
    "        return sum / len(x_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.w * x + self.b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972e699",
   "metadata": {
    "papermill": {
     "duration": 0.01617,
     "end_time": "2023-05-13T22:41:28.253482",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.237312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, consider the following simple training examples, which you should also find familiar, that represent the square feet and prices of houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a794c191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.288456Z",
     "iopub.status.busy": "2023-05-13T22:41:28.287347Z",
     "iopub.status.idle": "2023-05-13T22:41:28.292075Z",
     "shell.execute_reply": "2023-05-13T22:41:28.291308Z"
    },
    "papermill": {
     "duration": 0.024211,
     "end_time": "2023-05-13T22:41:28.294091",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.269880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = [1.0, 2.0]\n",
    "y_train = [300.0, 500.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b4d0a",
   "metadata": {
    "papermill": {
     "duration": 0.01566,
     "end_time": "2023-05-13T22:41:28.326223",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.310563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As demonstrated in the related Exploration, we can instantiate, train and make predictions with our UnivariateLinearRegressor as follows. Notice how we first instantiate our UnivariateLinearRegressor with a _single_ weight, and the bias and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b9d446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.360576Z",
     "iopub.status.busy": "2023-05-13T22:41:28.359841Z",
     "iopub.status.idle": "2023-05-13T22:41:28.367401Z",
     "shell.execute_reply": "2023-05-13T22:41:28.366360Z"
    },
    "papermill": {
     "duration": 0.027844,
     "end_time": "2023-05-13T22:41:28.370075",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.342231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of a 1,000 sqft house is 301.4502082643262\n",
      "The price of a 2,000 sqft house is 488.7867275295899\n",
      "The price of an 8,000 sqft house is 1612.805843121172\n"
     ]
    }
   ],
   "source": [
    "regressor = UnivariateLinearRegressor(0, 0, 0.1)\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "small_house_price = regressor.predict(1.0)\n",
    "print(f\"The price of a 1,000 sqft house is {small_house_price}\")\n",
    "\n",
    "medium_house_price = regressor.predict(2.0)\n",
    "print(f\"The price of a 2,000 sqft house is {medium_house_price}\")\n",
    "\n",
    "big_house_price = regressor.predict(8.0)\n",
    "print(f\"The price of an 8,000 sqft house is {big_house_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf869a12",
   "metadata": {
    "papermill": {
     "duration": 0.015722,
     "end_time": "2023-05-13T22:41:28.402305",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.386583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Observing the results, we can see that the model has made its way toward converging on its line of best fit. However, we are intentionally limiting the amount of training in `fit`, and therefore truncating the training. Again, we are limiting this only for simplicity and experimentation. Try increasing the steps of gradient descent to 500 and re-run the code cells, and notice that the predictions become more accurate.\n",
    "\n",
    "This concludes a review of our UnivariateLinearRegressor. Notice that this implementation intentionally handles only one dimension of input. In the example above, this one dimension is the size in square feet of a house.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a6a25",
   "metadata": {
    "papermill": {
     "duration": 0.016249,
     "end_time": "2023-05-13T22:41:28.434776",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.418527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The MultipleLinearRegressor\n",
    "\n",
    "While our simple UnivariateLinearRegressor works well for just a single dimension of input, we would like to make predictions based on multiple features, such as square feet, number of bedrooms, the number of floors, and the age of a house.\n",
    "\n",
    "To demonstrate your understanding of features, vectors and gradient descent, try completing the implementation of a MultipleLinearRegressor. We begin with the implementation below, which has a complete `predict` method and method stubs for `fit` and the partial derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88142528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.469224Z",
     "iopub.status.busy": "2023-05-13T22:41:28.468087Z",
     "iopub.status.idle": "2023-05-13T22:41:28.473099Z",
     "shell.execute_reply": "2023-05-13T22:41:28.472040Z"
    },
    "papermill": {
     "duration": 0.024647,
     "end_time": "2023-05-13T22:41:28.475363",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.450716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implement fit, _d_cost_function_w and _d_cost_function_b, to represent an appropriate gradient descent algorithm that trains our multiple linear regression model. \\n\n",
    "# When complete, you should see the model produce price predictions that \"best fit\" the simple training data above. Here are some suggestions for completing your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f5774",
   "metadata": {
    "papermill": {
     "duration": 0.015677,
     "end_time": "2023-05-13T22:41:28.507642",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.491965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define the logic in MultipleLinearRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6364d14f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.541488Z",
     "iopub.status.busy": "2023-05-13T22:41:28.541086Z",
     "iopub.status.idle": "2023-05-13T22:41:28.554942Z",
     "shell.execute_reply": "2023-05-13T22:41:28.553841Z"
    },
    "papermill": {
     "duration": 0.033867,
     "end_time": "2023-05-13T22:41:28.557433",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.523566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultipleLinearRegressor:\n",
    "\n",
    "    def __init__(self, w = [], b = 0, alpha = 0.01):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for _ in range(0, 10):\n",
    "            dw = self._d_cost_function_w(x_train, y_train)\n",
    "            db = self._d_cost_function_b(x_train, y_train)\n",
    "            self.w = [wi - self.alpha * di for wi, di in zip(self.w, dw)]\n",
    "            self.b = self.b - self.alpha * db\n",
    "    \n",
    "    def _d_cost_function_w(self, x_train, y_train):\n",
    "        # of rows in the training datasets\n",
    "        m = len(x_train)\n",
    "        # of attributes in the training datasets\n",
    "        dw = [0] * len(x_train[0])\n",
    "        for i in range(m):\n",
    "            x = x_train[i]\n",
    "            y = y_train[i]\n",
    "            y_pred = self.predict(x)\n",
    "            for j in range(len(x)):\n",
    "                dw[j] += (y_pred - y) * x[j]\n",
    "        for j in range(len(x)):\n",
    "            dw[j] = dw[j] / m\n",
    "        return dw\n",
    "\n",
    "    def _d_cost_function_b(self, x_train, y_train):\n",
    "        m = len(x_train)\n",
    "        db = 0\n",
    "        for i in range(m):\n",
    "            x = x_train[i]\n",
    "            y = y_train[i]\n",
    "            y_pred = self.predict(x)\n",
    "            db += (y_pred - y)\n",
    "        db /= m\n",
    "        return db\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self._dot_product(self.w, x) + self.b\n",
    "\n",
    "    def _dot_product(self, a, b):\n",
    "        return sum(pair[0] * pair[1] for pair in zip(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10cad0",
   "metadata": {
    "papermill": {
     "duration": 0.015566,
     "end_time": "2023-05-13T22:41:28.589052",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.573486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we shall see in a moment, your goal will be to implement `fit` and `_d_cost_function_w` and `_d_cost_function_b`. For now, let's take a look at the training set and see how our current implementation behaves.\n",
    "\n",
    "We'll start with a simple contrived data set with four examples, already split for you. Each training example in `x_train` represents the size, number of bedrooms, number of floors and the age of a house. Each value in `y_train` represents the price of the house in thousands of dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4438da",
   "metadata": {
    "papermill": {
     "duration": 0.015663,
     "end_time": "2023-05-13T22:41:28.620522",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.604859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Apply the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b533ada2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.653614Z",
     "iopub.status.busy": "2023-05-13T22:41:28.653204Z",
     "iopub.status.idle": "2023-05-13T22:41:28.659804Z",
     "shell.execute_reply": "2023-05-13T22:41:28.658600Z"
    },
    "papermill": {
     "duration": 0.025936,
     "end_time": "2023-05-13T22:41:28.662146",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.636210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = [\n",
    "    [2104.0, 5.0, 1.0, 45.0],\n",
    "    [1416.0, 3.0, 2.0, 40.0],\n",
    "    [1534.0, 3.0, 2.0, 30.0],\n",
    "    [852.0, 2.0, 1.0, 36.0]\n",
    "]\n",
    "y_train = [460.0, 232.0, 315.0, 178.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57145c76",
   "metadata": {
    "papermill": {
     "duration": 0.015492,
     "end_time": "2023-05-13T22:41:28.693476",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.677984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice that `x_train` now contains vectors representing the features of each house, and each vector contains four features. Since we know that our linear regression model will need one weight for each feature, we should instantiate it with a _vector_ of weights, along with a bias and our learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f8e274",
   "metadata": {
    "papermill": {
     "duration": 0.015461,
     "end_time": "2023-05-13T22:41:28.725126",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.709665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initialize the w, b and apply smaller learning rate to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63afa91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.758369Z",
     "iopub.status.busy": "2023-05-13T22:41:28.757982Z",
     "iopub.status.idle": "2023-05-13T22:41:28.763678Z",
     "shell.execute_reply": "2023-05-13T22:41:28.762362Z"
    },
    "papermill": {
     "duration": 0.025355,
     "end_time": "2023-05-13T22:41:28.766144",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.740789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor = MultipleLinearRegressor([0, 0, 0, 0], 0, 0.0000001)\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419ba5f",
   "metadata": {
    "papermill": {
     "duration": 0.015844,
     "end_time": "2023-05-13T22:41:28.797928",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.782084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Even though our implementation is incomplete, we can try to make some predictions. Notice that, to make a prediction, we should provide the `predict` method with a vector of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85216fb",
   "metadata": {
    "papermill": {
     "duration": 0.015465,
     "end_time": "2023-05-13T22:41:28.829098",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.813633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Test result and show the predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45eea1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:28.862566Z",
     "iopub.status.busy": "2023-05-13T22:41:28.862181Z",
     "iopub.status.idle": "2023-05-13T22:41:28.871133Z",
     "shell.execute_reply": "2023-05-13T22:41:28.869929Z"
    },
    "papermill": {
     "duration": 0.028838,
     "end_time": "2023-05-13T22:41:28.873593",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.844755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is 460 thousand dollars\n",
      "The predicted price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is 398.9660711700676 thousand dollars\n",
      "The actual price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is 232 thousand dollars\n",
      "The predicted price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is 268.54879763449054 thousand dollars\n",
      "The actual price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is 315 thousand dollars\n",
      "The predicated price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is 290.8686778691389 thousand dollars\n",
      "The actual price of an 852 sqft house with 2 bedrooms, 1 floor, that is 36 years old is 178 thousand dollars\n",
      "The predicted price of this house is 161.63738104041943\n"
     ]
    }
   ],
   "source": [
    "# 'Test Run' Code Cell, Referred to in \"What to Do\" #2.\n",
    "\n",
    "first_house_price = regressor.predict([2104.0, 5.0, 1.0, 45.0])\n",
    "print(f\"The actual price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is 460 thousand dollars\")\n",
    "print(f\"The predicted price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is {first_house_price} thousand dollars\")\n",
    "\n",
    "second_house_price = regressor.predict([1416.0, 3.0, 2.0, 40.0])\n",
    "print(f\"The actual price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is 232 thousand dollars\")\n",
    "print(f\"The predicted price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is {second_house_price} thousand dollars\")\n",
    "\n",
    "third_house_price = regressor.predict([1534.0, 3.0, 2.0, 30.0])\n",
    "print(f\"The actual price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is 315 thousand dollars\")\n",
    "print(f\"The predicated price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is {third_house_price} thousand dollars\")\n",
    "\n",
    "small_house_price = regressor.predict([852.0, 2.0, 1.0, 36.0])\n",
    "print(f\"The actual price of an 852 sqft house with 2 bedrooms, 1 floor, that is 36 years old is 178 thousand dollars\")\n",
    "print(f\"The predicted price of this house is {small_house_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f86a66",
   "metadata": {
    "papermill": {
     "duration": 0.0163,
     "end_time": "2023-05-13T22:41:28.906416",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.890116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice how, for each example, our MultipleLinearRegressor model is predicting a 0.\n",
    "\n",
    "Our goal is to complete the implementation of MultipleLinearRegressor, ensuring that we can properly train it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01338a",
   "metadata": {
    "papermill": {
     "duration": 0.015621,
     "end_time": "2023-05-13T22:41:28.937975",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.922354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What to Do\n",
    "\n",
    "Implement `fit`, `_d_cost_function_w` and `_d_cost_function_b`, to represent an appropriate gradient descent algorithm that trains our multiple linear regression model. When complete, you should see the model produce price predictions that \"best fit\" the simple training data above. Here are some suggestions for completing your implementation.\n",
    "\n",
    "1. Modify the existing MultipleLinearRegressor class definition above.\n",
    "2. Run your code frequently, using _Run All_ and running the code in the \"Test Run\" code cell above.\n",
    "2. Draw inspiration from the UnivariateLinearRegressor - the structure of gradient descent remains the same, we just need to handle a vector of weights and features.\n",
    "3. Consider replicating the small steps taken in the exploration. Start with `fit`.\n",
    "4. Review the Exploration content and familiarize yourself with the expressions for computing the partial derivatives with respect to `w` and `b` when using a _vector_ of weights and features.\n",
    "5. Implement just _one_ of the partial derivative functions first, and verify that the prediction output has changed.\n",
    "6. For convenience, you can create a new code cell with the class definition, data, instantiation and usage all in one code cell if you wish. But when complete, please be sure that you remove it, and that the MultipleLinearRegressor class definition above is complete.\n",
    "\n",
    "The best tip for thinking about this challenge is to become intimately familiar with the expressions for computing the gradients, or partial derivatives, for w and b. Then, try first working out on paper how your implementation of these computations might work, given the vector of weights and features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bb089",
   "metadata": {
    "papermill": {
     "duration": 0.015914,
     "end_time": "2023-05-13T22:41:28.969723",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.953809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ’¡ Conclusion\n",
    "\n",
    "The problem solving process:\n",
    "1) Started with fit function first. The logic is similar with UnivariateLinearRegressor and the only difference between them is in multiplelinear regression, there will be the vector of regression coefficients or weights associated with that. So I write a for loop when I do self.w.\n",
    "\n",
    "2) I created nested for loop inside another for loop to calculate vector of regression coefficients w and the other for loop is to calculate predict errors. But in the UnivariateLinearRegressor, there is only one indepent variable, for loop is used for calculate the predict errors.\n",
    "\n",
    "3) I write function to calculate b.\n",
    "\n",
    "\n",
    "After that, I test my result. However, it returns the negative values for the predict price. I go back to change the learning rate to a really small number.\n",
    "\n",
    "There are several limitations: \n",
    "1) The size of the training dataset is small and it is hard to find the pattern.\n",
    "\n",
    "2) We also need to scale the datasets to get better performance. But since the size of the training is so small. Scaling the dataset won't help much.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc500428",
   "metadata": {
    "papermill": {
     "duration": 0.016312,
     "end_time": "2023-05-13T22:41:29.002043",
     "exception": false,
     "start_time": "2023-05-13T22:41:28.985731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2: Predicting California Housing Prices\n",
    "\n",
    "_Attribution: Special thanks to Dr. Roi Yehoshua_\n",
    "\n",
    "In this, the second, part of this notebook, you will construct a guided experiment to analyze the quality of a linear regression model for predicting real housing prices. We'll use a version of the [california housing data](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html) by Kelley and Barry. Take a moment now to [familiarize yourself with the version of this data set provded by sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html), and you can take a look at [a version of this data on Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices). (Note that, the version on Kaggle has an extra column, ocean_proximity, which you should ignore.)\n",
    "\n",
    "As you progress through this notebook, complete each code cell, run them, and complete the Knowledge Checks.\n",
    "\n",
    "We'll begin by loading the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c520c0",
   "metadata": {
    "papermill": {
     "duration": 0.016383,
     "end_time": "2023-05-13T22:41:29.034958",
     "exception": false,
     "start_time": "2023-05-13T22:41:29.018575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Loading the Data Set\n",
    "\n",
    "For convenience, we shall rely on the \"california housing set\" provided by scikit-learn. We'll first import a few typical libraries, and fetch the data set.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "np.random.seed(0)\n",
    "data = fetch_california_housing(as_frame = True)\n",
    "print(data.DESCR)\n",
    "```\n",
    "\n",
    "Try doing the same in a code cell here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c088074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:29.069482Z",
     "iopub.status.busy": "2023-05-13T22:41:29.069107Z",
     "iopub.status.idle": "2023-05-13T22:41:33.885243Z",
     "shell.execute_reply": "2023-05-13T22:41:33.884094Z"
    },
    "papermill": {
     "duration": 4.836661,
     "end_time": "2023-05-13T22:41:33.888074",
     "exception": false,
     "start_time": "2023-05-13T22:41:29.051413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "np.random.seed(0)\n",
    "data = fetch_california_housing(as_frame = True)\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c5a08",
   "metadata": {
    "papermill": {
     "duration": 0.015815,
     "end_time": "2023-05-13T22:41:33.920145",
     "exception": false,
     "start_time": "2023-05-13T22:41:33.904330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert the dataset to a pandas DataFrame for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43d069",
   "metadata": {
    "papermill": {
     "duration": 0.015724,
     "end_time": "2023-05-13T22:41:33.951953",
     "exception": false,
     "start_time": "2023-05-13T22:41:33.936229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Apply statistic analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f991f079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:33.985880Z",
     "iopub.status.busy": "2023-05-13T22:41:33.985484Z",
     "iopub.status.idle": "2023-05-13T22:41:33.990968Z",
     "shell.execute_reply": "2023-05-13T22:41:33.990066Z"
    },
    "papermill": {
     "duration": 0.025119,
     "end_time": "2023-05-13T22:41:33.993029",
     "exception": false,
     "start_time": "2023-05-13T22:41:33.967910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create pandas dataframe\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a7f0af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.027227Z",
     "iopub.status.busy": "2023-05-13T22:41:34.026810Z",
     "iopub.status.idle": "2023-05-13T22:41:34.085474Z",
     "shell.execute_reply": "2023-05-13T22:41:34.084304Z"
    },
    "papermill": {
     "duration": 0.078766,
     "end_time": "2023-05-13T22:41:34.087911",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.009145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704  \n",
       "std       10.386050      2.135952      2.003532  \n",
       "min        0.692308     32.540000   -124.350000  \n",
       "25%        2.429741     33.930000   -121.800000  \n",
       "50%        2.818116     34.260000   -118.490000  \n",
       "75%        3.282261     37.710000   -118.010000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a26536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.123330Z",
     "iopub.status.busy": "2023-05-13T22:41:34.122643Z",
     "iopub.status.idle": "2023-05-13T22:41:34.130120Z",
     "shell.execute_reply": "2023-05-13T22:41:34.129315Z"
    },
    "papermill": {
     "duration": 0.027677,
     "end_time": "2023-05-13T22:41:34.132420",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.104743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        float64\n",
       "HouseAge      float64\n",
       "AveRooms      float64\n",
       "AveBedrms     float64\n",
       "Population    float64\n",
       "AveOccup      float64\n",
       "Latitude      float64\n",
       "Longitude     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b94ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.167532Z",
     "iopub.status.busy": "2023-05-13T22:41:34.167132Z",
     "iopub.status.idle": "2023-05-13T22:41:34.184845Z",
     "shell.execute_reply": "2023-05-13T22:41:34.183819Z"
    },
    "papermill": {
     "duration": 0.038018,
     "end_time": "2023-05-13T22:41:34.187198",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.149180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0       False     False     False      False       False     False     False   \n",
       "1       False     False     False      False       False     False     False   \n",
       "2       False     False     False      False       False     False     False   \n",
       "3       False     False     False      False       False     False     False   \n",
       "4       False     False     False      False       False     False     False   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635   False     False     False      False       False     False     False   \n",
       "20636   False     False     False      False       False     False     False   \n",
       "20637   False     False     False      False       False     False     False   \n",
       "20638   False     False     False      False       False     False     False   \n",
       "20639   False     False     False      False       False     False     False   \n",
       "\n",
       "       Longitude  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "20635      False  \n",
       "20636      False  \n",
       "20637      False  \n",
       "20638      False  \n",
       "20639      False  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf7464d",
   "metadata": {
    "papermill": {
     "duration": 0.017205,
     "end_time": "2023-05-13T22:41:34.222164",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.204959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ðŸ’¡ Knowledge Check 1\n",
    "\n",
    "The datasets is about California Housing datasets. It contains 20640 rows and total 9 attributes including 8 numeric, predictive attributes and 1 the target variable in the datasets. For these 9 attributes, the data type is float64 and the 9 attributes are continuous variable. The target variables is the median house values for California districts. There is no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b96fac",
   "metadata": {
    "papermill": {
     "duration": 0.016868,
     "end_time": "2023-05-13T22:41:34.256315",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.239447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that our data set is loaded, let's explore what we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea16d9",
   "metadata": {
    "papermill": {
     "duration": 0.016828,
     "end_time": "2023-05-13T22:41:34.290067",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.273239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Exploring the Data Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a75c79",
   "metadata": {
    "papermill": {
     "duration": 0.016632,
     "end_time": "2023-05-13T22:41:34.323801",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.307169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's quickly investigate some examples in the data set. Since `data` is a sklearn Bunch object, we can obtain the pandas DataFrame and investigate its shape, to determine the number of rows and columns, and to inspect the first few rows of data.\n",
    "\n",
    "```python\n",
    "print(data.frame.shape)\n",
    "data.frame.head()\n",
    "```\n",
    "\n",
    "Go ahead and investigate the first few rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ec7bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.360079Z",
     "iopub.status.busy": "2023-05-13T22:41:34.359631Z",
     "iopub.status.idle": "2023-05-13T22:41:34.379745Z",
     "shell.execute_reply": "2023-05-13T22:41:34.378529Z"
    },
    "papermill": {
     "duration": 0.041163,
     "end_time": "2023-05-13T22:41:34.382119",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.340956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.frame.shape)\n",
    "data.frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe367c0",
   "metadata": {
    "papermill": {
     "duration": 0.017339,
     "end_time": "2023-05-13T22:41:34.417418",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.400079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ðŸ’¡ Knowledge Check 2\n",
    "\n",
    "\n",
    "\n",
    "From the shape, it shows that there are 20640 rows and 9 attributes in the datasets.\n",
    "\n",
    "From the head, it shows that the first 5 rows about the datasets. It provides us a general sense about the datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32668e5",
   "metadata": {
    "papermill": {
     "duration": 0.017273,
     "end_time": "2023-05-13T22:41:34.452456",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.435183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3: Preparing Training and Test Sets\n",
    "\n",
    "To train and test our linear regression model, we will need to split our data set. We'll use the `data` and `target` attributes of the Bunch to retrieve the feature set and target prediction values. Then, we'll reach for the handy `train_test_split` method from sklearn.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_attributes, prices = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_attributes, prices, test_size = 0.2)\n",
    "X_train.head()\n",
    "```\n",
    "\n",
    "Go ahead and split the data set into training and test sets here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ef30af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.489612Z",
     "iopub.status.busy": "2023-05-13T22:41:34.489234Z",
     "iopub.status.idle": "2023-05-13T22:41:34.598195Z",
     "shell.execute_reply": "2023-05-13T22:41:34.597072Z"
    },
    "papermill": {
     "duration": 0.130338,
     "end_time": "2023-05-13T22:41:34.600866",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.470528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12069</th>\n",
       "      <td>4.2386</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.723077</td>\n",
       "      <td>1.169231</td>\n",
       "      <td>228.0</td>\n",
       "      <td>3.507692</td>\n",
       "      <td>33.83</td>\n",
       "      <td>-117.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15925</th>\n",
       "      <td>4.3898</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.326622</td>\n",
       "      <td>1.100671</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>3.322148</td>\n",
       "      <td>37.73</td>\n",
       "      <td>-122.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>3.9333</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.668478</td>\n",
       "      <td>1.046196</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2.777174</td>\n",
       "      <td>33.83</td>\n",
       "      <td>-118.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>1.4653</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.383495</td>\n",
       "      <td>1.009709</td>\n",
       "      <td>749.0</td>\n",
       "      <td>3.635922</td>\n",
       "      <td>34.01</td>\n",
       "      <td>-118.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>3.1765</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.119792</td>\n",
       "      <td>1.043403</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1.970486</td>\n",
       "      <td>34.08</td>\n",
       "      <td>-118.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "12069  4.2386       6.0  7.723077   1.169231       228.0  3.507692     33.83   \n",
       "15925  4.3898      52.0  5.326622   1.100671      1485.0  3.322148     37.73   \n",
       "11162  3.9333      26.0  4.668478   1.046196      1022.0  2.777174     33.83   \n",
       "4904   1.4653      38.0  3.383495   1.009709       749.0  3.635922     34.01   \n",
       "4683   3.1765      52.0  4.119792   1.043403      1135.0  1.970486     34.08   \n",
       "\n",
       "       Longitude  \n",
       "12069    -117.55  \n",
       "15925    -122.44  \n",
       "11162    -118.00  \n",
       "4904     -118.26  \n",
       "4683     -118.36  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_attributes, prices = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_attributes, prices, test_size = 0.2)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd46298",
   "metadata": {
    "papermill": {
     "duration": 0.017544,
     "end_time": "2023-05-13T22:41:34.636096",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.618552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The # of examples in the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a32c811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.673410Z",
     "iopub.status.busy": "2023-05-13T22:41:34.673032Z",
     "iopub.status.idle": "2023-05-13T22:41:34.678279Z",
     "shell.execute_reply": "2023-05-13T22:41:34.677226Z"
    },
    "papermill": {
     "duration": 0.026927,
     "end_time": "2023-05-13T22:41:34.680631",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.653704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16512\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaef415",
   "metadata": {
    "papermill": {
     "duration": 0.017572,
     "end_time": "2023-05-13T22:41:34.716171",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.698599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The # of examples in the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed8f2b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.754598Z",
     "iopub.status.busy": "2023-05-13T22:41:34.754182Z",
     "iopub.status.idle": "2023-05-13T22:41:34.759742Z",
     "shell.execute_reply": "2023-05-13T22:41:34.758679Z"
    },
    "papermill": {
     "duration": 0.027599,
     "end_time": "2023-05-13T22:41:34.761923",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.734324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4128\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27508932",
   "metadata": {
    "papermill": {
     "duration": 0.017713,
     "end_time": "2023-05-13T22:41:34.797658",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.779945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ðŸ’¡ Knowledge Check 3\n",
    "\n",
    "\n",
    "\n",
    "The # of examples in the training sets is 16512, the # of examples in the test sets is 4128."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47701c65",
   "metadata": {
    "papermill": {
     "duration": 0.018221,
     "end_time": "2023-05-13T22:41:34.833971",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.815750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4: Pre-Processing and Training\n",
    "\n",
    "Before applying our regression model, we would like to standardize the training set. To do this, we'll use the sklearn StandardScaler. Once we standardize the data, we will use it to train a linear regression model. In our case, we will experiment with the scikit-learn [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html), a linear regression model that trains via stochastic gradient descent (SGD). Please be sure to take a look at [the documentation for SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html).\n",
    "\n",
    "To demonstrate a new feature in scikit-learn, and to give you some new ideas in your own future work, we will illustrate a small \"machine learning pipeline,\" using the scikit-learn [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class.\n",
    "\n",
    "A Pipeline is handy for \"setting up\" multiple pre-processing steps that will run one after the other. The Pipeline can also end in a training step with a model. This enables us to provide the Pipeline our training data, and with one method call, complete both pre-processing and training in one step.\n",
    "\n",
    "We'll import the necessary libraries, create our Pipeline, fill it with a StandardScalar and SGDRegressor, and run the Pipeline.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', SGDRegressor())\n",
    "])\n",
    "```\n",
    "\n",
    "Try importing the necessary libraries and building your Pipeline below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aee19d",
   "metadata": {
    "papermill": {
     "duration": 0.018438,
     "end_time": "2023-05-13T22:41:34.870459",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.852021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Apply StandardScaler and SGDRegressor components in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90172aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:34.909527Z",
     "iopub.status.busy": "2023-05-13T22:41:34.909142Z",
     "iopub.status.idle": "2023-05-13T22:41:35.023072Z",
     "shell.execute_reply": "2023-05-13T22:41:35.021914Z"
    },
    "papermill": {
     "duration": 0.136276,
     "end_time": "2023-05-13T22:41:35.025866",
     "exception": false,
     "start_time": "2023-05-13T22:41:34.889590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', SGDRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560785f2",
   "metadata": {
    "papermill": {
     "duration": 0.017725,
     "end_time": "2023-05-13T22:41:35.062325",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.044600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Change another meaningful name for the StandardScaler and SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31486e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:35.101080Z",
     "iopub.status.busy": "2023-05-13T22:41:35.100618Z",
     "iopub.status.idle": "2023-05-13T22:41:35.105798Z",
     "shell.execute_reply": "2023-05-13T22:41:35.105049Z"
    },
    "papermill": {
     "duration": 0.027221,
     "end_time": "2023-05-13T22:41:35.107912",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.080691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('SGPregressor', SGDRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385bf53",
   "metadata": {
    "papermill": {
     "duration": 0.018915,
     "end_time": "2023-05-13T22:41:35.144749",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.125834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With our Pipeline created, we can now invoke the Pipeline's `fit` method, passing it the training data. Behind the scenes, the Pipeline will standardize our training data, and also invoke our SGDRegressor's `fit` method with the transformed training data.\n",
    "\n",
    "```\n",
    "pipeline.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Try kicking off the Pipeline below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec357a1a",
   "metadata": {
    "papermill": {
     "duration": 0.017733,
     "end_time": "2023-05-13T22:41:35.180367",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.162634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fits the pipeline model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50bfd5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:35.218156Z",
     "iopub.status.busy": "2023-05-13T22:41:35.217773Z",
     "iopub.status.idle": "2023-05-13T22:41:35.259990Z",
     "shell.execute_reply": "2023-05-13T22:41:35.258848Z"
    },
    "papermill": {
     "duration": 0.064258,
     "end_time": "2023-05-13T22:41:35.262506",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.198248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;SGPregressor&#x27;, SGDRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;SGPregressor&#x27;, SGDRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('SGPregressor', SGDRegressor())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb4a9e",
   "metadata": {
    "papermill": {
     "duration": 0.018061,
     "end_time": "2023-05-13T22:41:35.299285",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.281224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With our model now trained, let us analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc927e",
   "metadata": {
    "papermill": {
     "duration": 0.017889,
     "end_time": "2023-05-13T22:41:35.335410",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.317521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ðŸ’¡ Knowledge Check 4\n",
    "\n",
    "Investigate the parameters passed to the Pipeline initializer. Notice our use of the strings `'scaler'` and `'regressor'`. What purpose do these serve, and are we required to use those specific strings, or can we \"make up\" our own meaningful names for each component of the Pipeline?\n",
    "\n",
    "\n",
    "The strings 'scaler' and 'regressor' used in the Pipeline initialier sever as the keys for the pipeline components. The purpose is to identify and reference each step in the Pipeline when performing operations such as fitting, transforming or accessing specific components.\n",
    "\n",
    "We could make up our own meaningful names for each component of the Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9cb5e",
   "metadata": {
    "papermill": {
     "duration": 0.017552,
     "end_time": "2023-05-13T22:41:35.371270",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.353718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 5: Model Validation\n",
    "\n",
    "We have conducted an initial round of training using a data set that may or may not have strong linear tendencies, and we have employed a basic, unconfigured SGDRegressor model to see what baseline quality we can achieve. Let's investigate the \"coefficient of determination,\" R^2, via the model's `score` method. We will invoke this `score` method via the Pipeline, since it has ownership of our SGDRegressor model. We would love to see a value as close to 1.0 as possible.\n",
    "\n",
    "We can generate an R^2 score with both the training data and the test data to validate the quality of our model.\n",
    "\n",
    "```python\n",
    "training_score = pipeline.score(X_train, y_train)\n",
    "print(f\"Training score: {training_score:.6f}\")\n",
    "\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Test score: {test_score:.6f}\")\n",
    "```\n",
    "\n",
    "Go ahead and generate and print the score based on the training data, and the score based on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f5eb218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:35.409528Z",
     "iopub.status.busy": "2023-05-13T22:41:35.409148Z",
     "iopub.status.idle": "2023-05-13T22:41:35.426903Z",
     "shell.execute_reply": "2023-05-13T22:41:35.425488Z"
    },
    "papermill": {
     "duration": 0.041405,
     "end_time": "2023-05-13T22:41:35.430880",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.389475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: -154.744672\n",
      "Test score: -1413.434270\n"
     ]
    }
   ],
   "source": [
    "training_score = pipeline.score(X_train, y_train)\n",
    "print(f\"Training score: {training_score:.6f}\")\n",
    "\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Test score: {test_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fa35b",
   "metadata": {
    "papermill": {
     "duration": 0.03815,
     "end_time": "2023-05-13T22:41:35.508185",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.470035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ðŸ’¡ Knowledge Check 5\n",
    "\n",
    "What are the scores for the training and test sets? What do they indicate? Are they good? How do you know? (Hint: Have you read the documentation for the `score` method of SGDRegressor?)\n",
    "\n",
    "The training score is -154.744672 and test score is -1413.434270. The score() method of SGDRegressor returns the coefficient of determination R^2 of the predictions. The R^2 score measures the proportion of the variance in the target variable that can be explained by the linear regression model.\n",
    "\n",
    "The R^s score ranges from negative infinity to 1. 1 indicates a perfect fit, 0 indicates that the model performs no better than a constant baseline (it always predicts the expected values of y, disregarding the input features) and negative scores indicate that model fits the data poorly.\n",
    "\n",
    "Both scores are negive and tells us that the model fits the data relatively poor. The negative R^2 scores indicate that the linear regression model fails to explain the variance in the target variable better than a constant baseline. It fails to explain the relationship between independent variables and dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08a1db",
   "metadata": {
    "papermill": {
     "duration": 0.018127,
     "end_time": "2023-05-13T22:41:35.563610",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.545483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 6: Adjusting the Model (Experiment)\n",
    "\n",
    "If we spend time reviewing the documentation of SGDRegressor, we find that the default instantiation uses particular default hyperparameters. Now it's your turn. Based on the concepts in the course and your understanding of linear regression, how might you \"tune\" the SGDRegressor instance in the Pipeline?\n",
    "\n",
    "Try setting up a new Pipeline as an experiment, and try passing different parameter configurations to SGDRegressor's initializer, and investigate the results. You might set up your experiment like the following. Notice how we have specified a `penalty` of `None` as a demonstrated experiment.\n",
    "\n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', SGDRegressor(penalty = None))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "training_score = pipeline.score(X_train, y_train)\n",
    "print(f\"Training score: {training_score:.6f}\")\n",
    "\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Test score: {test_score:.6f}\")\n",
    "```\n",
    "\n",
    "Create a similar experiment here, and try a few different initialization parameters for SGDRegressor. How might you increase its performance score? (Think about the important concepts of a linear regression model that uses gradient descent. Be sure to try customizing the most important hyperparameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbb35593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T22:41:35.602409Z",
     "iopub.status.busy": "2023-05-13T22:41:35.601368Z",
     "iopub.status.idle": "2023-05-13T22:41:35.680202Z",
     "shell.execute_reply": "2023-05-13T22:41:35.678984Z"
    },
    "papermill": {
     "duration": 0.102336,
     "end_time": "2023-05-13T22:41:35.684151",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.581815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.601767\n",
      "Test score: 0.582980\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', SGDRegressor(penalty='l1', alpha=0.01, max_iter=1000, random_state=42, eta0 = 0.1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "training_score = pipeline.score(X_train, y_train)\n",
    "print(f\"Training score: {training_score:.6f}\")\n",
    "\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Test score: {test_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f25b89d",
   "metadata": {
    "papermill": {
     "duration": 0.038415,
     "end_time": "2023-05-13T22:41:35.761544",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.723129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "See if you can make any improvement to the training and test scores. Then, see if your models can achieve a score between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2028e",
   "metadata": {
    "papermill": {
     "duration": 0.024562,
     "end_time": "2023-05-13T22:41:35.822873",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.798311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ðŸ’¡ Knowledge Check 6\n",
    "\n",
    "Based on the concepts in the Explorations regarding linear regression and gradient descent, what is perhaps the single most important hyperparameter for a linear regression model? What SGDRegressor initialization parameter lets you specify the value for this important hyperparameter?\n",
    "\n",
    "The single most important hyperparameter for a linear regression is the learning rate (eta0). The learning rate determines the step size at each iteration of the gradient decent optimization algorithm. I keep other parameter the same and try different eta0 from 0.0001, 0.001, 0.01 and 0.1). It turns out that eta0 = 0.1 is the most important hyperparameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6339d0f5",
   "metadata": {
    "papermill": {
     "duration": 0.018196,
     "end_time": "2023-05-13T22:41:35.859793",
     "exception": false,
     "start_time": "2023-05-13T22:41:35.841597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "(Replace this writing prompt with your conclusion.) Summarize what you've seen and done here in Part 2, starting with the domain, problem and data set. Mention three things that were most notable in this process, whether it's related to exploration, preprocessing, configuring, training, or evaluating. If you put in the effort to try to improve the SGDRegressor, describe what you did and what led you to try what you did, and describe the results. Conclude with some statements or questions about the model score, the model being used, and the data set. Make suggestions about what you might do next to either improve the score or conclude with an explanation of whether you would continue to use a linear model.\n",
    "\n",
    "\n",
    "The most 3 noteable things:\n",
    "1) In the exploring dataset process, I use statistic method to explore the datasets to check out the min, max, count, etc to help me better understand the dataset.\n",
    "\n",
    "2) In the pre-processing process and training process, we use StandardScaler to scale the datasets. It ensures that the input features are appropriately scaled before being passes to the SGDRegressor.\n",
    "\n",
    "3) In the step 5 model validation, it turns out the negative values. I adjust the model by changing the hyperparameter in the model. I found out that the learning rate eta0 is the most important hyperparameter for a linear regression after tried several differnent learning rate.\n",
    "\n",
    "\n",
    "Next steps:\n",
    "1) Apply more training and test datasets to feed into the mode. There is not enough data to help the model to learn the pattern.\n",
    "\n",
    "2) Try different scaler and regressor to see if model turns into better results.Maybe other model might be able to fit the data pattern before. However, I need to do further analysis to validate my assumptions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.487927,
   "end_time": "2023-05-13T22:41:36.800122",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-13T22:41:16.312195",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
